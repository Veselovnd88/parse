from bs4 import BeautifulSoup
import requests
import json
import time
import csv
import openpyxl


class WrongFile(BaseException):
    pass


class Html:
    """Создается экземпляр класса, далее пользуемся методами"""

    def __init__(self, prefix=None):
        self.prefix = prefix



    def get_content(self, url, params=None):
        HEADERS = {'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:71.0)'
                                 ' Gecko/20100101 Firefox/71.0', 'accept': '*/*'}
        self.url = url
        self.params = params
        response = requests.get(self.url, headers=HEADERS, params=self.params, timeout=5)
        if response.status_code == 200:
            self.content = response.text
            time.sleep(3)
        else:
            print('Error')

    def get_from_file(self, filename):
        try:
            with open(filename, 'r') as file:
                self.content = file.read()
        except FileNotFoundError as err:
            print('Неправильное имя файла ', err)
            raise WrongFile

    def parse(self):
        """Start to parse html file, returning dictionary with elements"""
        print('Start parsing ')
        soup = BeautifulSoup(self.content, 'html.parser')
        data = soup.find_all('div', class_="omega thirteen columns")
        self.pagename = soup.find('h1', class_='product-title').get_text().replace('/', '')
        picts = soup.find_all('div', class_="alpha three columns textcenter")
        # print(picts)
        self.newdict = {}
        # print(data)
        pictlst = []
        for item in picts:
            pict = item.find('img').get('src')
            pictlst.append(pict)
        k = 0  # переменная индекс списка piclst
        for item in data:
            title = item.find('p').get_text()
            url = item.find('a').get('href')
            lst = []
            acchead = item.find('thead').find_next('tr').find_next('th').get_text()
            stylehead = item.find('thead').find_next('tr').find_next('th'). \
                find_next('th').get_text()
            rangehead = item.find('thead').find_next('tr').find_next('th'). \
                find_next('th').find_next('th').get_text()
            accbody = item.find('tbody').find_next('td').get_text()
            stylebody = item.find('tbody').find_next('td').find_next('td').get_text()
            rangebody = item.find('tbody').find_next('td').find_next('td'). \
                find_next('td').get_text()
            lst.append(
                {acchead: accbody,
                 stylehead: stylebody,
                 rangehead: rangebody,
                 'url': url,
                 'picturl': 'https://www.ashcroft.eu' + pictlst[k]})
            k += 1  # прибавляем чтобы идти по списке
            self.newdict[title] = lst
        print('Parsing finished' + self.pagename)

        return self.newdict

    def parse_card(self):

        print('Start parsing cards')
        soup = BeautifulSoup(self.content, 'html.parser')
        self.pagename = soup.find('div', class_="center-column-content product-detail").find_next('h1').text
        basic = soup.find('div', id="overview-tab-content")
        "Блок полей для парсинга"
        bigphotos = soup.find('ul', class_='slides').find_next('a').get('href')
        smallphotos = soup.find('ul', class_='slides').find_next('li').get('data-thumb')
        description = basic.find_next('p').text
        features = basic.find_next('h5').text
        features_desr = basic.find_next('ul')
        featureslst = []
        for item in features_desr:
            featureslst.append(item.text)
        featuresstr = '; '.join(featureslst)
        spec = basic.find_next('h5').find_next('h5').text
        spec_descr = basic.find_next('ul').find_next('ul')
        speclst = []
        for i in spec_descr:
            speclst.append(i.text)
        specstr = '; '.join(speclst)
        appl = soup.find('div', id="applications-tab-content"). \
            text.replace('/', '-').replace('\\', '-')
        """ Этот блок приводит в нормальный вид описание сфер применения"""
        begin = 0
        fields = ''

        for i in range(len(appl)):
            if appl[i].islower() and appl[i + 1].isupper():
                fields += appl[begin + 1:i + 1] + ', '
                begin = i
        fields += appl[begin + 1:]
        datasheet = soup.find('div', class_='product-details widget'). \
            find_next('a', class_='detail-button').get('href')
        spaces = datasheet.count(' ')
        cleands = datasheet
        if spaces > 0: # меняем пробелы на %20 чтобы файл скачивался
            for i in range(spaces):
                cleands = datasheet.replace(' ', '%20')


        self.newdict = {self.pagename: {
            'Description': description,
            features: featuresstr,
            spec: specstr,
            'Application': fields.strip(),
            'Large_picture': self.prefix + bigphotos,
            'Small_picture': self.prefix + smallphotos,
            'Datasheet': self.prefix[:-3] + cleands
        }
        }
        print('Parsing card ' + self.pagename + ' completed')
        return self.newdict
        # TODO - конверация  и excel

    def to_json(self):
        """ Method for the saving json file with the results dict"""
        print('Создаем .json файл')
        with open(self.pagename + '.json', 'w', encoding='utf8') as write_file:
            json.dump(self.newdict, write_file, indent=2)
        print('Создание файла json выполнено')

    def to_csv_product(self):
        """Create csv file"""
        print('Start to create .csv file')
        dictkeys = list(self.newdict[self.pagename].keys())

        """
        Превратил этот блок в функцию
        columns = []
        meaning = []
        for i in range(len(dictkeys)):
            columns.append(dictkeys[i])
            meaning.append(self.newdict[self.pagename][dictkeys[i]])
        """
        with open(self.pagename + '.csv', 'w', newline='', encoding='utf8') as csvfile:
            writer = csv.writer(csvfile, delimiter=',')
            # writer.writeheader()
            writer.writerow(self.table_columns(dictkeys))
            counter = 0
            writer.writerow(self.table_meaning(dictkeys))
        print('Creating .csv file is finished')

    def table_columns(self,lst):
        """ Функция делает шапку таблицы"""
        columns = []
        meaning = []
        for i in range(len(lst)):
            columns.append(lst[i])
            meaning.append(self.newdict[self.pagename][lst[i]])
        return columns

    def table_meaning(self,lst):
        """Функция заполняет значения таблицы под шапкой"""
        columns = []
        meaning = []
        for i in range(len(lst)):
            columns.append(lst[i])
            meaning.append(self.newdict[self.pagename][lst[i]])
        return meaning

    def to_excel_product(self, groupname = self.pagename,qnt=0):
        """Create excel file"""
        print('Start to make .xlsx file')
        file = openpyxl.Workbook()
        """Создание формы нового файла"""
        sheetsource = file.active
        sheetsource.title = groupname
        dictkeys = list(self.newdict[self.pagename].keys())
        head = self.table_columns(dictkeys)
        fill = self.table_meaning(dictkeys)
        for i in range(len(head)):
            sheetsource.cell(row=1, column=i+1).value = head[i]
            sheetsource.cell(row=2+qnt,column=i+1).value=fill[i]

        file.save(groupname+ '.xlsx')
        print('Creating .xlsx is finished, filename ' + self.pagename)

    def to_csv_line(self):
        """Create csv file"""
        print('Start to create .csv file')
        with open(self.pagename + '.csv', 'w', newline='', encoding='utf8') as csvfile:
            columns = ['Model', 'Accuracy', 'Dial Size and Style', 'Range', 'Url', 'Picture']
            writer = csv.writer(csvfile, delimiter=',')

            # writer.writeheader()
            writer.writerow(columns)
            counter = 0
            for key in self.newdict:
                writer.writerow(
                    [key,
                     self.newdict[key][0][list(self.newdict[key][0].keys())[0]],
                     self.newdict[key][0][list(self.newdict[key][0].keys())[1]],
                     self.newdict[key][0][list(self.newdict[key][0].keys())[2]],
                     self.newdict[key][0][list(self.newdict[key][0].keys())[3]],
                     self.newdict[key][0][list(self.newdict[key][0].keys())[4]],

                     ]
                )
        print('Creating .csv file is finished')

    def to_excel_line(self):
        """Create excel file"""
        print('Start to make .xlsx file')
        file = openpyxl.Workbook()
        """Создание формы нового файла"""
        sheetsource = file.active
        sheetsource.title = self.pagename
        columns = ['Model', 'Accuracy', 'Dial Size and Style', 'Range', 'Url', 'Picture']
        sheetsource['A1'] = columns[0]
        sheetsource['B1'] = columns[1]
        sheetsource['C1'] = columns[2]
        sheetsource['D1'] = columns[3]
        sheetsource['E1'] = columns[4]
        sheetsource['F1'] = columns[4]
        k = 2
        columnslst = ['A', 'B', 'C', 'D', 'E', 'F']
        for key in self.newdict:
            print(key)
            sheetsource[columnslst[0] + str(k)] = key.strip()
            sheetsource[columnslst[1] + str(k)] = self.newdict[key][0][list(self.newdict[key][0].keys())[0]]
            sheetsource[columnslst[2] + str(k)] = self.newdict[key][0][list(self.newdict[key][0].keys())[1]]
            sheetsource[columnslst[3] + str(k)] = self.newdict[key][0][list(self.newdict[key][0].keys())[2]]
            sheetsource[columnslst[4] + str(k)] = self.newdict[key][0][list(self.newdict[key][0].keys())[3]]
            sheetsource[columnslst[5] + str(k)] = self.newdict[key][0][list(self.newdict[key][0].keys())[4]]
            k += 1
        file.save(self.pagename + '.xlsx')
        print('Creating .xlsx is finished, filename ' + self.pagename)


"""
web = 'https://www.ashcroft.eu/en'
URL = 'https://www.ashcroft.eu/en/products/products.html'
HEADERS = {'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:71.0)'
                         ' Gecko/20100101 Firefox/71.0', 'accept': '*/*'}

new = Html()
done = [34, 62, 38, 36, 57, 35, 37, 73, 45, 70, 46, 47, 39, 40,
             65, 66,50, 49, 48, 51, 53, 64, 54, 61, 67, 68, 55,]
gidnumber = [56]
bad = [72]

#new.get_from_file('process.html')
    newdict = new.parse()
    new.to_csv()
    new.to_json()
    new.to_excel()

# TODO посмотреть верхние пределы списков, по странице 74
# TODO сделать так чтобы хорошие страницы отправлялись в список done
"""
